Index: architectures.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import torch\r\nimport torchaudio\r\nimport torch.nn as nn\r\n\r\n\r\nclass SimpleCNN(nn.Module):\r\n    def __init__(self):\r\n        super().__init__()\r\n        conv_layers = []\r\n        self.name = 'SimpleCNN'\r\n        # First Convolution Block with Relu and Batch Norm. Use Kaiming Initialization\r\n        self.conv1 = nn.Conv2d(1, 4, kernel_size=(8, 8), stride=(4, 4), padding=(2, 2))\r\n        self.relu1 = nn.ReLU()\r\n        self.bn1 = nn.BatchNorm2d(4)\r\n\r\n        # Second Convolution Block\r\n        self.conv2 = nn.Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\r\n        self.relu2 = nn.ReLU()\r\n        self.bn2 = nn.BatchNorm2d(16)\r\n\r\n        # Third Convolution Block\r\n        self.conv3 = nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\r\n        self.relu3 = nn.ReLU()\r\n        self.bn3 = nn.BatchNorm2d(32)\r\n\r\n        # Fourth Convolution Block\r\n        self.conv4 = nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\r\n        self.relu4 = nn.ReLU()\r\n        self.bn4 = nn.BatchNorm2d(64)\r\n\r\n        # Linear Classifier\r\n        self.ap = nn.AdaptiveAvgPool2d(output_size=1)\r\n        self.lin = nn.Linear(in_features=16, out_features=8)\r\n\r\n    def forward(self, x):\r\n        x = self.conv1(x)\r\n        x = self.relu1(x)\r\n        a1 = torch.flatten(x, 2, 3)\r\n        x = self.bn1(x)\r\n        x = self.conv2(x)\r\n        x = self.relu2(x)\r\n        a2 = torch.flatten(x, 2, 3)\r\n        x = self.bn2(x)\r\n        x = self.ap(x)\r\n        x = x.view(x.shape[0], -1)\r\n        x = self.lin(x)\r\n        return x, a1, a2\r\n\r\n\r\nclass Res2DBlock(nn.Module):\r\n    expansion = 1 #we don't use the block.expansion here\r\n\r\n    def __init__(self, inplanes, planes, stride=1,padding = 1):\r\n        super().__init__()\r\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size = 3, stride=stride,\r\n                     padding=padding, bias=False)\r\n        self.bn1 = nn.BatchNorm2d(planes)\r\n        self.relu = nn.ReLU(inplace=True)\r\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size = 3, stride=1,\r\n                     padding=padding, bias=False)\r\n        self.bn2 = nn.BatchNorm2d(planes)\r\n        self.downsample = nn.Sequential(\r\n                nn.Conv2d(inplanes, planes, 1, stride, bias=False),\r\n                nn.BatchNorm2d(planes))\r\n        self.stride = stride\r\n\r\n    def forward(self, x):\r\n        identity = x\r\n        out = self.conv1(x)\r\n        out = self.relu(out)\r\n        out = self.conv2(out)\r\n        out = self.bn2(out)\r\n        identity = self.downsample(x)\r\n        out += identity\r\n        out = self.relu(out)\r\n        return out\r\n\r\n\r\nclass ResNet(nn.Module):\r\n\r\n    def __init__(self, FN=16, num_classes=8, p_dropout=None):\r\n        super().__init__()\r\n\r\n        self.FN = FN\r\n        if FN == 128:\r\n            self.name = 'ResNet34-XL'\r\n        elif FN == 64:\r\n            self.name = 'ResNet34-L'\r\n        elif FN == 32:\r\n            self.name = 'ResNet34-M'\r\n        elif FN == 16:\r\n            self.name = 'ResNet34-S'\r\n        else:\r\n            self.name = 'ResNet34'\r\n        layers = [3, 4, 6, 3]\r\n        self.c1 = nn.Conv2d(1, FN, kernel_size=7, stride=2, padding=3, bias=False)\r\n        self.bn1 = nn.BatchNorm2d(FN)\r\n        self.relu = nn.ReLU(inplace=True)\r\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\r\n        self.layer1 = self._make_layer(FN, FN, layers[0])\r\n        self.layer2 = self._make_layer(FN, FN * 2, layers[1], stride=2)\r\n        self.avgpool = nn.AdaptiveAvgPool2d(7)\r\n        self.fc = nn.Linear(FN * 98, num_classes)\r\n        self.p_dropout = p_dropout\r\n        if p_dropout:\r\n            self.dropout = nn.Dropout(p=p_dropout)\r\n\r\n    def _make_layer(self, inplanes, planes, blocks, stride=1):\r\n        layers = []\r\n        layers.append(Res2DBlock(inplanes, planes, stride))\r\n\r\n        self.inplanes = planes\r\n\r\n        for _ in range(1, blocks):\r\n            layers.append(Res2DBlock(self.inplanes, planes))\r\n\r\n        return nn.Sequential(*layers)\r\n\r\n    def forward(self, x):\r\n        x = self.c1(x)\r\n        x = self.bn1(x)\r\n        x = self.relu(x)\r\n        x = self.maxpool(x)\r\n\r\n        x = self.layer1(x)\r\n        x = self.layer2(x)\r\n\r\n        x = self.avgpool(x)\r\n        x = torch.flatten(x, 1)\r\n        x = self.fc(x)\r\n        if self.p_dropout:\r\n            x = self.dropout(x)\r\n\r\n        return x\r\n\r\n\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/architectures.py b/architectures.py
--- a/architectures.py	(revision 91ef7fecd564575ab310bddaa314d5e3bb8fab1d)
+++ b/architectures.py	(date 1682859826053)
@@ -134,3 +134,64 @@
         return x
 
 
+class SimpleCNN2(nn.Module):
+    def __init__(self, activation='ReLU'):
+        super().__init__()
+        self.name = 'SimpleCNN'
+        assert activation in ['ReLU', 'tanh'], "Activation must be either 'ReLU' or 'tanh'"
+
+        # Choose the activation function
+        if activation == 'ReLU':
+            self.activation = nn.ReLU
+        else:
+            self.activation = nn.Tanh
+
+        # First Convolution Block with Activation and Batch Norm. Use Kaiming Initialization
+        self.conv1 = nn.Conv2d(1, 4, kernel_size=(8, 8), stride=(4, 4), padding=(2, 2))
+        self.act1 = self.activation()
+        self.bn1 = nn.BatchNorm2d(4)
+
+        # Second Convolution Block
+        self.conv2 = nn.Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
+        self.act2 = self.activation()
+        self.bn2 = nn.BatchNorm2d(16)
+
+        # Third Convolution Block
+        self.conv3 = nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
+        self.act3 = self.activation()
+        self.bn3 = nn.BatchNorm2d(32)
+
+        # Fourth Convolution Block
+        self.conv4 = nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
+        self.act4 = self.activation()
+        self.bn4 = nn.BatchNorm2d(64)
+
+        # Linear Classifier
+        self.ap = nn.AdaptiveAvgPool2d(output_size=1)
+        self.lin = nn.Linear(in_features=64, out_features=8)
+
+    def forward(self, x):
+        x = self.conv1(x)
+        x = self.act1(x)
+        a1 = torch.flatten(x, 2, 3)
+        x = self.bn1(x)
+
+        x = self.conv2(x)
+        x = self.act2(x)
+        a2 = torch.flatten(x, 2, 3)
+        x = self.bn2(x)
+
+        x = self.conv3(x)
+        x = self.act3(x)
+        a3 = torch.flatten(x, 2, 3)
+        x = self.bn3(x)
+
+        x = self.conv4(x)
+        x = self.act4(x)
+        a4 = torch.flatten(x, 2, 3)
+        x = self.bn4(x)
+
+        x = self.ap(x)
+        x = x.view(x.shape[0], -1)
+        x = self.lin(x)
+        return x, a1, a2, a3, a4
Index: main.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import os\r\nimport time\r\nfrom collections import defaultdict\r\n\r\nimport numpy as np\r\nimport pandas as pd\r\nimport matplotlib.pyplot as plt\r\nfrom sklearn.preprocessing import LabelBinarizer\r\n\r\nimport torch\r\nimport torchaudio\r\nimport torch.nn as nn\r\nfrom torch.utils.data import Dataset\r\nfrom torchsummary import summary\r\n\r\nfrom utils import load\r\nfrom dataloader import FMA2D_spec\r\nfrom architectures import SimpleCNN, ResNet\r\nfrom simplebinmi import bin_calc_information2\r\n\r\n#import kde\r\nimport kde_torch as kde\r\n#import keras.backend as K\r\n\r\n\r\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n\r\nDATA_DIR = './data/fma_small'\r\n\r\n# download data first from these links:\r\n# curl -O https://os.unil.cloud.switch.ch/fma/fma_metadata.zip\r\n# curl -O https://os.unil.cloud.switch.ch/fma/fma_small.zip\r\n\r\ntracks = load('./data/fma_metadata/tracks.csv')\r\nsubset = tracks.index[tracks['set', 'subset'] <= 'small']\r\n\r\ntracks = tracks.loc[subset][:1000]\r\ntrain = tracks.index[tracks['set', 'split'] == 'training']\r\nval = tracks.index[tracks['set', 'split'] == 'validation']\r\ntest = tracks.index[tracks['set', 'split'] == 'test']\r\n\r\nlabels_onehot = LabelBinarizer().fit_transform(tracks['track', 'genre_top'])\r\nlabels_onehot = pd.DataFrame(labels_onehot, index=tracks.index)\r\nlabels_onehot_np = np.array(labels_onehot)\r\n\r\nNUM_LABELS = 8\r\nlabelixs = {}\r\ny = np.argmax(labels_onehot_np, axis=1)\r\nfor i in range(NUM_LABELS):\r\n    labelixs[i] = y == i\r\n\r\nlabelprobs = np.mean(y, axis=0)\r\n\r\nBATCH = 256\r\nEPOCHS = 100\r\naugment_prob = 0.8\r\n\r\n# create a training dataset and dataloader\r\ndataset_train = FMA2D_spec(DATA_DIR, train, labels_onehot, transforms=False)\r\ndataloader = torch.utils.data.DataLoader(dataset_train, batch_size=BATCH, shuffle=True)\r\n\r\n# create a validation dataset and dataloader\r\ndataset_valid = FMA2D_spec(DATA_DIR, val, labels_onehot, transforms=False)\r\nval_dataloader = torch.utils.data.DataLoader(dataset_valid, batch_size=BATCH, shuffle=True)\r\n\r\n# define the loss function and the optimizer\r\nloss_fn = nn.CrossEntropyLoss()\r\n\r\n# Lee 2017\r\n# SGD optimizer\r\n#optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, nesterov=True)\r\n#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.2, patience=5)\r\n\r\nfrom utils import plot_spectrogram\r\nfor spec, label, ixs in dataloader:\r\n    #print(spec.size(), ixs)\r\n    #plot_spectrogram(spec[0])\r\n    input_size = spec.size()[2]\r\n    break\r\n\r\np_dropout = 0.3\r\n#model = ResNet(FN=64, p_dropout=p_dropout)\r\nmodel = SimpleCNN()\r\nmodel.to(device)\r\n\r\n\r\n#summary(model, (1, 128, 1290))\r\n\r\n#------------KDE functions\r\n# nats to bits conversion factor\r\nnats2bits = 1.0/np.log(2)\r\n#upper/lower entropy estimates\r\nnoise_variance = 1e-3  # Added Gaussian noise variance\r\nbinsize = 0.07  # size of bins for binning method\r\n\r\n# Functions to return upper and lower bounds on entropy of layer activity\r\n#Klayer_activity = K.placeholder(ndim=2)  # Keras placeholder\r\n#entropy_func_upper = torch.function([Klayer_activity,], [kde.entropy_estimator_kl(Klayer_activity, noise_variance),])\r\n#entropy_func_lower = torch.function([Klayer_activity,], [kde.entropy_estimator_bd(Klayer_activity, noise_variance),])\r\ndef entropy_func_upper(activity):\r\n    return kde.entropy_estimator_kl(activity, noise_variance)\r\ndef entropy_func_lower(activity):\r\n    return kde.entropy_estimator_bd(activity, noise_variance)\r\n#------------------------\r\n\r\n# Adam optimizer01\r\nlr = 0.01\r\noptimizer = torch.optim.Adam(model.parameters())\r\n\r\ntimestamp = time.strftime(\"apr%d_t%H%M\", time.gmtime())\r\nmodel_name = f\"{model.name}_B{BATCH}_E{EPOCHS}_LR{lr}_pD{p_dropout}_A{augment_prob}_{timestamp}\"\r\n\r\ni = 0\r\nrunning_loss = 0.0\r\nbest_val_loss = float('inf')  # initialize the best validation loss\r\n\r\n# train the model\r\nacc_tr = []\r\nacc_val = []\r\nloss_tr = []\r\nloss_val = []\r\nmi_array = []\r\nmi2_array = []\r\nmi3_array = []\r\nmi4_array = []\r\nactivity = np.zeros((1000, 4, 10304))\r\nactivity2 = np.zeros((1000, 16, 2576))\r\nt0 = time.time()\r\nprev_a = 0\r\nfor epoch in range(EPOCHS):\r\n    # evaluate the model on the training dataset\r\n    train_correct = 0\r\n    train_total = 0\r\n    for spectrogram, label, ixs in dataloader:\r\n        model.train()\r\n        label = label.to(device)\r\n        train_label = torch.argmax(label, dim=1)\r\n\r\n        # forward pass\r\n        spectrogram = spectrogram.squeeze(0)\r\n        spectrogram = spectrogram.unsqueeze(1)\r\n\r\n        spectrogram = spectrogram.to(device)\r\n        output, a1, a2 = model(spectrogram)\r\n        activity[ixs] = a1.cpu().detach().numpy()\r\n        activity2[ixs] = a2.cpu().detach().numpy()\r\n\r\n        loss = loss_fn(output, label)\r\n\r\n        cepochdata = defaultdict(list)\r\n\r\n        # backward pass\r\n        optimizer.zero_grad()\r\n        model.zero_grad()\r\n        loss.backward()\r\n        optimizer.step()\r\n\r\n        # Update the learning rate\r\n        # scheduler.step(loss)\r\n\r\n        _, train_predicted = torch.max(output.data, 1)\r\n        train_total += train_label.size(0)\r\n        train_correct += (train_predicted == train_label).sum().item()\r\n        # print statistics\r\n        i += 1\r\n        running_loss += loss.item()\r\n\r\n    loss = running_loss / len(dataloader)\r\n    loss_tr.append(loss)\r\n    print('[%d, %5d subsamples] Training loss: %.3f' % (epoch + 1, i * BATCH, loss))\r\n    running_loss = 0\r\n    # evaluate the model on the validation dataset\r\n    val_loss = 0.0\r\n    val_correct = 0\r\n    val_total = 0\r\n    model.eval()\r\n    with torch.no_grad():\r\n        for val_spectrogram, val_label, ixs in val_dataloader:\r\n            val_label = val_label.to(device)\r\n            val_label = torch.argmax(val_label, dim=1)\r\n\r\n            val_spectrogram = val_spectrogram.squeeze(0)\r\n            val_spectrogram = val_spectrogram.unsqueeze(1)\r\n            val_spectrogram = val_spectrogram.to(device)\r\n            val_output, a1, a2 = model(val_spectrogram)\r\n            activity[ixs] = a1.cpu().detach().numpy()\r\n            activity2[ixs] = a2.cpu().detach().numpy()\r\n            val_loss += loss_fn(val_output, val_label).item()\r\n            _, val_predicted = torch.max(val_output.data, 1)\r\n            val_total += val_label.size(0)\r\n            val_correct += (val_predicted == val_label).sum().item()\r\n\r\n    loss = val_loss / len(val_dataloader)\r\n    loss_val.append(loss)\r\n    val_acc = val_correct / val_total\r\n    tr_acc = train_correct / train_total\r\n    acc_tr.append(tr_acc)\r\n    acc_val.append(val_acc)\r\n    t1 = time.time()\r\n    t = (t1 - t0) / 60\r\n    # Save the model if the validation loss is the best seen so far\r\n    if loss < best_val_loss:\r\n        best_val_loss = loss\r\n        best_val_acc = val_acc\r\n        best_tr_acc = tr_acc\r\n        best_state_dict = model.state_dict()\r\n    print(\r\n        '[{:.4f} min] Validation Loss: {:.4f} | Validation Accuracy: {:.4f} | Training Accuracy: {:.4f}'.format(t, loss,\r\n                                                                                                                val_acc,\r\n                                                                                                                tr_acc))\r\n    #mi = bin_calc_information2(labelixs, activity[:, 0, :], 0.005)\r\n    #print(activity[:, 0, :])\r\n    #mi_array.append(mi)\r\n#-----------KDE estimates\r\n    # Compute marginal entropies\r\n    h_upper = entropy_func_upper([activity[:, 0, :], ])#[0]\r\n    h_lower = entropy_func_lower([activity[:, 0, :], ])#[0]\r\n\r\n    # Layer activity given input. This is simply the entropy of the Gaussian noise\r\n    hM_given_X = kde.kde_condentropy(activity[:, 0, :], noise_variance)\r\n\r\n    # Compute conditional entropies of layer activity given output\r\n    hM_given_Y_upper = 0.\r\n    hM_given_Y_lower = 0.\r\n    for i in range(NUM_LABELS):\r\n        hcond_upper = entropy_func_upper([activity[labelixs[i], :], ])[0]\r\n        hM_given_Y_upper += labelprobs[i] * hcond_upper\r\n        hcond_lower = entropy_func_lower([activity[labelixs[i], :], ])[0]\r\n        hM_given_Y_lower += labelprobs[i] * hcond_lower\r\n\r\n    cepochdata['MI_XM_upper'].append(nats2bits * (h_upper - hM_given_X))\r\n    cepochdata['MI_YM_upper'].append(nats2bits * (h_upper - hM_given_Y_upper))\r\n    cepochdata['H_M_upper'].append(nats2bits * h_upper)\r\n    pstr += 'upper: MI(X;M)=%0.3f, MI(Y;M)=%0.3f' % (cepochdata['MI_XM_upper'][-1], cepochdata['MI_YM_upper'][-1])\r\n\r\n    cepochdata['MI_XM_lower'].append(nats2bits * (h_lower - hM_given_X))\r\n    cepochdata['MI_YM_lower'].append(nats2bits * (h_lower - hM_given_Y_lower))\r\n    cepochdata['H_M_lower'].append(nats2bits * h_lower)\r\n    pstr += ' | lower: MI(X;M)=%0.3f, MI(Y;M)=%0.3f' % (cepochdata['MI_XM_lower'][-1], cepochdata['MI_YM_lower'][-1])\r\n#----------------------visualisation\r\nmi_array_kde = np.array(cepochdata)\r\nplt.scatter(mi_array_kde[:, 0], mi_array_kde[:, 1], label='Mutual Information L1')\r\nplt.xlabel('I(X,T)')\r\nplt.ylabel('I(Y,T)')\r\nplt.show()\r\n#----------------------\r\n#print(mi_array)\r\n#mi_array = np.array(mi_array)\r\n#np.save(timestamp, mi_array)\r\n\r\nplt.plot(loss_val, label='Validation loss')\r\nplt.plot(loss_tr, label='Training loss')\r\nplt.show()\r\n\r\nplt.plot(acc_val, label='Validation accuracy')\r\nplt.plot(acc_tr, label='Training accuracy')\r\nplt.show()\r\n\r\n#plt.scatter(mi_array[:, 0], mi_array[:, 1], label='Mutual Information L1')\r\n#plt.xlabel('I(X,T)')\r\n#plt.ylabel('I(Y,T)')\r\n#plt.show()\r\n\r\ntorch.save(best_state_dict, model_name + f'_VAL{best_val_acc}_TRAIN{best_tr_acc}.pt')\r\nprint('Finished Training')\r\n\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/main.py b/main.py
--- a/main.py	(revision 91ef7fecd564575ab310bddaa314d5e3bb8fab1d)
+++ b/main.py	(date 1682860796175)
@@ -16,12 +16,11 @@
 from utils import load
 from dataloader import FMA2D_spec
 from architectures import SimpleCNN, ResNet
+#from architectures import SimpleCNN2, ResNet
 from simplebinmi import bin_calc_information2
 
 #import kde
 import kde_torch as kde
-#import keras.backend as K
-
 
 device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
 
@@ -41,11 +40,11 @@
 
 labels_onehot = LabelBinarizer().fit_transform(tracks['track', 'genre_top'])
 labels_onehot = pd.DataFrame(labels_onehot, index=tracks.index)
-labels_onehot_np = np.array(labels_onehot)
+
 
 NUM_LABELS = 8
 labelixs = {}
-y = np.argmax(labels_onehot_np, axis=1)
+y = np.argmax(labels_onehot.to_numpy(), axis=1)
 for i in range(NUM_LABELS):
     labelixs[i] = y == i
 
@@ -54,6 +53,7 @@
 BATCH = 256
 EPOCHS = 100
 augment_prob = 0.8
+labels_onehot_np = np.array(labels_onehot)
 
 # create a training dataset and dataloader
 dataset_train = FMA2D_spec(DATA_DIR, train, labels_onehot, transforms=False)
@@ -73,21 +73,27 @@
 
 from utils import plot_spectrogram
 for spec, label, ixs in dataloader:
+    #print(spec.size())
+    #print(len(label))
+    #print(ixs)
+    #plot_spectrogram(spec[0])
     #print(spec.size(), ixs)
     #plot_spectrogram(spec[0])
     input_size = spec.size()[2]
     break
 
+#plot MI I(X,T) for conv blocks
 p_dropout = 0.3
 #model = ResNet(FN=64, p_dropout=p_dropout)
-model = SimpleCNN()
+#added a condition to allow to specify ReLU or tanh
+model = SimpleCNN(activation = "tanh")
+#model = SimpleCNN()
 model.to(device)
 
-
 #summary(model, (1, 128, 1290))
 
 #------------KDE functions
-# nats to bits conversion factor
+#nats to bits conversion factor
 nats2bits = 1.0/np.log(2)
 #upper/lower entropy estimates
 noise_variance = 1e-3  # Added Gaussian noise variance
@@ -119,14 +125,20 @@
 acc_val = []
 loss_tr = []
 loss_val = []
-mi_array = []
-mi2_array = []
-mi3_array = []
-mi4_array = []
+
+mi_array_a1 = []
+mi_array_a2 = []
+mi_array_a3 = []
+mi_array_a4 = []
+
 activity = np.zeros((1000, 4, 10304))
 activity2 = np.zeros((1000, 16, 2576))
+activity3 = np.zeros((1000, 32, 648))
+activity4 = np.zeros((1000, 64, 164))
+
 t0 = time.time()
 prev_a = 0
+
 for epoch in range(EPOCHS):
     # evaluate the model on the training dataset
     train_correct = 0
@@ -141,13 +153,16 @@
         spectrogram = spectrogram.unsqueeze(1)
 
         spectrogram = spectrogram.to(device)
-        output, a1, a2 = model(spectrogram)
+        #output, a1, a2 = model(spectrogram)
+        output, a1, a2, a3, a4 = model(spectrogram)
         activity[ixs] = a1.cpu().detach().numpy()
         activity2[ixs] = a2.cpu().detach().numpy()
+        activity3[ixs] = a3.cpu().detach().numpy()
+        activity4[ixs] = a4.cpu().detach().numpy()
 
         loss = loss_fn(output, label)
 
-        cepochdata = defaultdict(list)
+        #cepochdata = defaultdict(list)
 
         # backward pass
         optimizer.zero_grad()
@@ -182,9 +197,7 @@
             val_spectrogram = val_spectrogram.squeeze(0)
             val_spectrogram = val_spectrogram.unsqueeze(1)
             val_spectrogram = val_spectrogram.to(device)
-            val_output, a1, a2 = model(val_spectrogram)
-            activity[ixs] = a1.cpu().detach().numpy()
-            activity2[ixs] = a2.cpu().detach().numpy()
+            val_output, a1, a2, _, _ = model(val_spectrogram)
             val_loss += loss_fn(val_output, val_label).item()
             _, val_predicted = torch.max(val_output.data, 1)
             val_total += val_label.size(0)
@@ -208,59 +221,77 @@
         '[{:.4f} min] Validation Loss: {:.4f} | Validation Accuracy: {:.4f} | Training Accuracy: {:.4f}'.format(t, loss,
                                                                                                                 val_acc,
                                                                                                                 tr_acc))
-    #mi = bin_calc_information2(labelixs, activity[:, 0, :], 0.005)
-    #print(activity[:, 0, :])
-    #mi_array.append(mi)
-#-----------KDE estimates
+    #------KDE estimates
     # Compute marginal entropies
-    h_upper = entropy_func_upper([activity[:, 0, :], ])#[0]
-    h_lower = entropy_func_lower([activity[:, 0, :], ])#[0]
-
+    h_upper = entropy_func_upper([activity, ])
+    h_lower = entropy_func_lower([activity, ])
     # Layer activity given input. This is simply the entropy of the Gaussian noise
-    hM_given_X = kde.kde_condentropy(activity[:, 0, :], noise_variance)
+    hM_given_X = kde.kde_condentropy(activity, noise_variance)
 
     # Compute conditional entropies of layer activity given output
     hM_given_Y_upper = 0.
     hM_given_Y_lower = 0.
     for i in range(NUM_LABELS):
-        hcond_upper = entropy_func_upper([activity[labelixs[i], :], ])[0]
+        hcond_upper = entropy_func_upper([activity[labelixs[i], :, :], ])[0]
         hM_given_Y_upper += labelprobs[i] * hcond_upper
-        hcond_lower = entropy_func_lower([activity[labelixs[i], :], ])[0]
+        hcond_lower = entropy_func_lower([activity[:, labelixs[i], :, :], ])[0]
         hM_given_Y_lower += labelprobs[i] * hcond_lower
 
-    cepochdata['MI_XM_upper'].append(nats2bits * (h_upper - hM_given_X))
-    cepochdata['MI_YM_upper'].append(nats2bits * (h_upper - hM_given_Y_upper))
-    cepochdata['H_M_upper'].append(nats2bits * h_upper)
-    pstr += 'upper: MI(X;M)=%0.3f, MI(Y;M)=%0.3f' % (cepochdata['MI_XM_upper'][-1], cepochdata['MI_YM_upper'][-1])
+
+    mi_array_a1.append(mi_a1)
+    mi_array_a2.append(mi_a2)
+    mi_array_a3.append(mi_a3)
+    mi_array_a4.append(mi_a4)
+
+mi_array_a1 = np.array(mi_array_a1)
+mi_array_a2 = np.array(mi_array_a2)
+mi_array_a3 = np.array(mi_array_a3)
+mi_array_a4 = np.array(mi_array_a4)
+
+np.save(timestamp + '_MI_a1', mi_array_a1)
+np.save(timestamp + '_MI_a2', mi_array_a2)
+np.save(timestamp + '_MI_a3', mi_array_a3)
+np.save(timestamp + '_MI_a4', mi_array_a4)
 
-    cepochdata['MI_XM_lower'].append(nats2bits * (h_lower - hM_given_X))
-    cepochdata['MI_YM_lower'].append(nats2bits * (h_lower - hM_given_Y_lower))
-    cepochdata['H_M_lower'].append(nats2bits * h_lower)
-    pstr += ' | lower: MI(X;M)=%0.3f, MI(Y;M)=%0.3f' % (cepochdata['MI_XM_lower'][-1], cepochdata['MI_YM_lower'][-1])
-#----------------------visualisation
-mi_array_kde = np.array(cepochdata)
-plt.scatter(mi_array_kde[:, 0], mi_array_kde[:, 1], label='Mutual Information L1')
-plt.xlabel('I(X,T)')
-plt.ylabel('I(Y,T)')
+t = np.arange(len(mi_array_a1))
+plt.plot(t, mi_array_a1, label='MI Conv1')
+plt.plot(t, mi_array_a2, label='MI Conv2')
+plt.plot(t, mi_array_a3, label='MI Conv3')
+plt.plot(t, mi_array_a4, label='MI Conv4')
+
+plt.xlabel('Epochs')
+plt.ylabel('MI/Entropy(T)')
+plt.grid()
+plt.legend()
 plt.show()
-#----------------------
-#print(mi_array)
-#mi_array = np.array(mi_array)
-#np.save(timestamp, mi_array)
+
+fig, axs = plt.subplots(2, 2, figsize=(10, 10))
+fig.suptitle('MI/Entropy(T) vs Epochs for Conv Blocks')
 
-plt.plot(loss_val, label='Validation loss')
-plt.plot(loss_tr, label='Training loss')
+axs[0, 0].plot(t, mi_array_a1, label='MI Conv1', color='blue')
+axs[0, 0].set_title('Conv1')
+axs[0, 0].grid()
+axs[0, 0].set(ylabel='MI/Entropy(T)')
+
+axs[0, 1].plot(t, mi_array_a2, label='MI Conv2', color='orange')
+axs[0, 1].set_title('Conv2')
+axs[0, 1].grid()
+
+axs[1, 0].plot(t, mi_array_a3, label='MI Conv3', color='green')
+axs[1, 0].set_title('Conv3')
+axs[1, 0].grid()
+axs[1, 0].set(xlabel='Epochs', ylabel='MI/Entropy(T)')
+
+axs[1, 1].plot(t, mi_array_a4, label='MI Conv4', color='red')
+axs[1, 1].set_title('Conv4')
+axs[1, 1].grid()
+axs[1, 1].set(xlabel='Epochs')
+
 plt.show()
 
-plt.plot(acc_val, label='Validation accuracy')
-plt.plot(acc_tr, label='Training accuracy')
-plt.show()
-
-#plt.scatter(mi_array[:, 0], mi_array[:, 1], label='Mutual Information L1')
-#plt.xlabel('I(X,T)')
-#plt.ylabel('I(Y,T)')
-#plt.show()
-
 torch.save(best_state_dict, model_name + f'_VAL{best_val_acc}_TRAIN{best_tr_acc}.pt')
 print('Finished Training')
 
+
+
+
